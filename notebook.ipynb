{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7fbdb166-365d-44ea-9288-99a4baba1b56",
   "metadata": {},
   "source": [
    "### AWS Cloud Club UWaterloo\n",
    "\n",
    "# SageMaker workshop\n",
    "\n",
    "This workshop explores a tabular, [binary classification](https://en.wikipedia.org/wiki/Binary_classification) use-case with significant **class imbalance**: predicting if a passenger on the Titanic survived.\n",
    "\n",
    "In this notebook, you'll first tackle the challenge with AutoML using [Amazon SageMaker Canvas AutoML](https://docs.aws.amazon.com/sagemaker/latest/dg/canvas-build-model.html), and then dive deeper with [SageMaker built-in XGBoost algorithm](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html)\n",
    "\n",
    "## Contents\n",
    "\n",
    "> ℹ️ **Tip:** You can use the Table of Contents panel in the left sidebar on JupyterLab / SageMaker Studio, to view and navigate sections\n",
    "\n",
    "1. **[Prepare our environment](#Prepare-our-environment)**\n",
    "1. **[Fetch the example dataset](#Fetch-the-example-dataset)**\n",
    "1. **[SageMaker Canvas](#SageMaker-Canvas)**\n",
    "1. **[XGBoost](#XGBoost)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8118fe0-ce06-42e9-a3c3-aefa47c2bed0",
   "metadata": {},
   "source": [
    "## Prepare our environment\n",
    "\n",
    "To read datasets directly from Amazon S3 object storage to in-memory dataframes with Pandas, we'll need to install the [s3fs](https://s3fs.readthedocs.io/en/latest/) library which is not included by default in SageMaker Studio Distribution (at v1.9):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120df283-c7e3-4039-9b33-5bdb660ba56a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install s3fs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbcac64-5cba-4530-b3cb-5f9a06339f5b",
   "metadata": {},
   "source": [
    "To get started, we'll need to:\n",
    "\n",
    "- **Import** some useful libraries (as in any Python notebook)\n",
    "- **Configure** -\n",
    "    - The [Amazon S3 bucket](https://docs.aws.amazon.com/AmazonS3/latest/userguide/Welcome.html#CoreConcepts) and folder where **data** should be stored (to keep our environment tidy)\n",
    "    - The [IAM role](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles.html) defining what **permissions** the jobs you create will have\n",
    "- **Connect** to AWS in general (with [boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html)) and SageMaker in particular (with the [sagemaker SDK](https://sagemaker.readthedocs.io/en/stable/)), to use the cloud services\n",
    "\n",
    "Run the cell below, to set these up.\n",
    "\n",
    "> ℹ️ **Tip:** Just like in a regular [JupyterLab notebook](https://jupyterlab.readthedocs.io/en/stable/user/interface.html), you can run code cells by clicking in to target cell - and then pressing the play (▶️) button in the toolbar or `Shift+Enter` on the keyboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9e1b6a-41fc-4fb1-8194-76c2d96579d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Python Built-Ins:\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "\n",
    "# External Dependencies:\n",
    "import boto3  # General-purpose AWS SDK for Python\n",
    "import numpy as np  # For matrix operations and numerical processing\n",
    "import pandas as pd  # Tabular data utilities\n",
    "import sagemaker  # High-level SDK specifically for Amazon SageMaker\n",
    "from sagemaker.automl.automlv2 import (\n",
    "    AutoMLDataChannel,\n",
    "    AutoMLTabularConfig,\n",
    "    AutoMLV2 as AutoMLV2Estimator,\n",
    ")\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "\n",
    "# Local Helper Functions:\n",
    "import util\n",
    "\n",
    "# Setting up SageMaker parameters\n",
    "sgmk_session = sagemaker.Session()  # Connect to SageMaker APIs\n",
    "region = sgmk_session.boto_session.region_name  # The AWS Region we're using (e.g. 'us-east-1')\n",
    "bucket_name = sgmk_session.default_bucket()  # Select an Amazon S3 bucket\n",
    "bucket_prefix = \"awscc-sm/titanic\"  # Location in the bucket to store our files\n",
    "sgmk_role = sagemaker.get_execution_role()  # IAM Execution Role to use for permissions\n",
    "\n",
    "print(f\"s3://{bucket_name}/{bucket_prefix}\")\n",
    "print(sgmk_role)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3679792b-7352-4064-a449-035a68f2c6c4",
   "metadata": {},
   "source": [
    "## Fetch the example dataset\n",
    "\n",
    "This example uses [this dataset](https://www.kaggle.com/datasets/shubhamgupta012/titanic-dataset), which contains information about the passengers on the titanic.\n",
    "\n",
    "In the following cells we'll download the dataset locally, store it in Amazon S3, and **also** load a transformed copy into [Amazon SageMaker Feature Store](https://aws.amazon.com/sagemaker/feature-store/).\n",
    "\n",
    "> ℹ️ **Tip:** You can train and deploy models in SageMaker **without using** SageMaker Feature Store, but we introduce it in this example to show you to a wider range of SageMaker features."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ca7fa3a4",
   "metadata": {},
   "source": [
    "Unzip the archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f7a032",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip archive.zip\n",
    "!mkdir data\n",
    "!mv SVMtrain.csv ./data/titanic.csv\n",
    "!rm SVMtrain.csv\n",
    "!rm archive.zip"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0500646b",
   "metadata": {},
   "source": [
    "Upload the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145a4fcd-7c54-42d7-a6a9-09efe63fd59e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_data_path = os.path.join(\"data\", \"titanic.csv\")\n",
    "\n",
    "print(\"Uploading raw dataset to Amazon S3:\")\n",
    "raw_data_s3uri = f\"s3://{bucket_name}/{bucket_prefix}/raw.csv\"\n",
    "!aws s3 cp {raw_data_path} {raw_data_s3uri}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1c1a74-eb5f-4c9f-9bb4-bc147138f8f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "feature_group_name = \"awscc-sm-titanic\"\n",
    "print(\"Loading data to SageMaker Feature Store:\")\n",
    "\n",
    "util.data.load_sample_data(\n",
    "    raw_data_path,\n",
    "    fg_s3_uri=f\"s3://{bucket_name}/{bucket_prefix}/feature-store\",\n",
    "    feature_group_name=feature_group_name,\n",
    "    ignore_cols=[\n",
    "        \"PassengerId\"\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "030e72d9-8b36-4dc3-a43f-ddf892598b95",
   "metadata": {},
   "source": [
    "> ⏰ **You don't have to wait** for this cell to finish running: As soon as you reach the `Ingesting data...` step, you're ready to continue on to the next section!\n",
    "\n",
    "▶️ As soon as you reach the `Ingesting data...` stage, you'll be able to see your \"feature group\" in the SageMaker Feature Store catalog:\n",
    "\n",
    "- Open or switch to the tab where you've launched the SageMaker Studio home screen\n",
    "- Choose `Data > Feature Store` from the sidebar menu to open the Feature Store UI\n",
    "\n",
    "Note you can explore the catalog either by \"feature group\" (table), or searching for individual features themselves. Descriptions and some tags have already been populated for you, based on the dataset description from UCI.\n",
    "\n",
    "![](img/feature-store-features.png \"Screenshot of SMStudio Feature Store UI showing feature catalog\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "44b0be11-d5a8-4fe4-9f8a-b1c9426d9b15",
   "metadata": {},
   "source": [
    "## SageMaker Canvas\n",
    "\n",
    "SageMaker Canvas AutoML makes it easy to get started on tabular ML problems, even without extensive data preparation or writing any code. This is because:\n",
    "\n",
    "- AutoML will automatically explore multiple data pre-processing options, algorithms, and hyperparameters for you - to identify a high-performing model\n",
    "- Even if you **do** want to perform some manual feature engineering first, Canvas has direct integrations from [SageMaker Data Wrangler](https://aws.amazon.com/sagemaker/data-wrangler/) (SageMaker's low-code/no-code data preparation tool)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cedf0c-ead8-41b0-9b88-154db3acabe6",
   "metadata": {},
   "source": [
    "▶️ While your data finishes importing to SageMaker Feature Store, let's **start an AutoML experiment using the raw CSV file**\n",
    "\n",
    "1. **Open** the 🏠 *SageMaker Studio Home* page\n",
    "1. **Choose** `Canvas` from the *applications* sidebar menu\n",
    "1. **Click** the `Run Canvas` button to start the Canvas environment\n",
    "1. (⏰ Once Canvas starts, which could take a minute or two) **Click** `Open canvas` to launch the Canvas UI\n",
    "\n",
    "![](img/canvas-01-launch.png \"Screenshot of SageMaker Studio home showing 'Canvas' application selected, with buttons to stop and open Canvas\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb53a764-27e6-489d-9ac5-a4f0cd6bca37",
   "metadata": {},
   "source": [
    "▶️ Import the raw dataset to Canvas ready to build a model:\n",
    "\n",
    "- **Select** the `Datasets` tab from the left sidebar\n",
    "- **Click** `Import data > tabular` to launch the flow\n",
    "    - For **Dataset name**, enter `titanic`\n",
    "    - For **Data source**, select `Amazon S3`\n",
    "    - **Browse** to your data at: `Amazon S3/sagemaker-{your region and acct ID}/awscc-sm/titanic/raw.csv`\n",
    "- Once you've selected your raw CSV, **Click** `Preview` and then `Create dataset`\n",
    "\n",
    "![](img/canvas-02-datasets-list.png \"Screenshot of SageMaker Canvas Datasets tab showing expanded button to import a tabular dataset\")\n",
    "\n",
    "![](img/canvas-03-data-selection.png \"Screenshot of SageMaker Canvas dataset import flow showing Amazon S3 source with the raw CSV selected\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8f8cfc0f-6580-4bf5-b558-eedc869fc255",
   "metadata": {},
   "source": [
    "Once your dataset is imported successfully, you're ready to create a model from it.\n",
    "\n",
    "▶️ From the same Canvas Datasets list\n",
    "\n",
    "- **Select** your new `titanic` dataset by clicking on the checkbox\n",
    "- **Click** the `Create a model` button above the dataset list\n",
    "\n",
    "![](img/canvas-04-select-dataset.png \"Screenshot of Canvas dataset list with demo dataset selected and 'Create a model' button highlighted\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "48a601e6-5b31-4d55-b5e6-79f7fa50f90f",
   "metadata": {},
   "source": [
    "▶️ Configure your Canvas model:\n",
    "\n",
    "- For **Model name**, enter `awscc-uw-sm-canvas-model`\n",
    "- Leave the model type as the default *Predictive analysis*\n",
    "- For the **Target column**, select `Survived`\n",
    "- **Un-check** the data column `PassengerID` to **drop** it from the model\n",
    "- **Select** `Standard build` instead of the default 'Quick build' from the drop-down\n",
    "- Once you've verified the configuration, **Click \"Standard build\"** to start the model build process"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "385544cd-1bf1-44b1-a1dd-fa25ab982354",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "\n",
    "Another useful tool to build high-performing models quickly is the set of [built-in algorithms](https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html) offered by SageMaker for a wide range of use-cases.\n",
    "\n",
    "Instead of using Autopilot to automate the process of data pre-processing and hyperparameter tuning, we can directly use these built-in algorithms (or custom ones) for finer-grained control. In this example, we'll show the [XGBoost algorithm](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html).\n",
    "\n",
    "\n",
    "### Understand the algorithm requirements\n",
    "\n",
    "The first step to using any SageMaker built-in algorithm is understanding its overall characteristics and the interface it offers. Here we'll refer to:\n",
    "\n",
    "- The [algorithm docs](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html) to understand the **detail** of the **data formats** and **(hyper)-parameters** it supports - as well as sample notebooks\n",
    "- The [Common Parameters doc](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-algo-docker-registry-paths.html) to compare the **high-level configurations** and capabilities between algorithms.\n",
    "\n",
    "\n",
    "As discussed on the algorithm doc page, there are 2 ways to use XGBoost in SageMaker: As a pre-built algorithm (no script required), or as a framework (with your own custom training script).\n",
    "\n",
    "In this example, we'll use pre-built algorithm mode so only need to fetch the container image URI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c0d5df-16ba-4d30-a883-febf7210fba4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_uri = sagemaker.image_uris.retrieve(\"xgboost\", region=region, version=\"1.7-1\")\n",
    "print(image_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc7b804-1adc-4fca-b534-032edce80295",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Extract batch data from the SageMaker Feature Store\n",
    "\n",
    "Next, we'll extract a snapshot of data from the (offline/batch) SageMaker Feature Store via serverless SQL query with [Amazon Athena](https://aws.amazon.com/athena/), to prepare for model training.\n",
    "\n",
    "Feature Store **tracks the history** of records, allowing you to reproduce point-in-time snapshots even when features change over time.\n",
    "\n",
    "- **Example queries** for time-travel and other views are available through the SageMaker Studio Feature Store UI: From your Feature Group, switch to the \"Sample queries\" tab.\n",
    "- The additional `event_time`, `write_time`, `api_invocation_time`, `is_deleted` and `row_number` fields returned in the below query are metadata for this history tracking - so won't be used in the actual model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c144afc-a7e9-420e-93d9-3cdb22fac8cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_group = FeatureGroup(feature_group_name, sagemaker_session=sgmk_session)\n",
    "query = feature_group.athena_query()\n",
    "table_name = query.table_name\n",
    "\n",
    "data_extract_s3uri = f\"s3://{bucket_name}/{bucket_prefix}/data-extract\"\n",
    "!aws s3 rm --quiet --recursive {data_extract_s3uri}  # Clear any previous extractions\n",
    "print(f\"Querying feature store to extract snapshot at:\\n{data_extract_s3uri}\")\n",
    "query.run(\n",
    "    f\"\"\"\n",
    "    SELECT *\n",
    "    FROM\n",
    "        (SELECT *,\n",
    "        row_number()\n",
    "        OVER\n",
    "            (PARTITION BY \"PassengerID\"\n",
    "            ORDER BY \"EventTime\" DESC, Api_Invocation_Time DESC, write_time DESC)\n",
    "        AS row_number\n",
    "        FROM \"sagemaker_featurestore\".\"{table_name}\"\n",
    "        WHERE \"EventTime\" <= {time.time()})\n",
    "    WHERE row_number = 1 AND NOT is_deleted;\n",
    "    \"\"\",\n",
    "    output_location=data_extract_s3uri,\n",
    ")\n",
    "query.wait()\n",
    "\n",
    "full_df = query.as_dataframe()\n",
    "print(f\"Got {len(full_df)} records\")\n",
    "full_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17151b2f-40d5-4390-8717-25ead7d4ce80",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Split and prepare datasets\n",
    "\n",
    "From the [Input and Output Interface section](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html#InputOutput-XGBoost) of the algorithm doc, we know that XGBoost expects CSV or LibSVM data inputs for training, and optionally validation.\n",
    "\n",
    "Some extra data preparation is also required because (at the time of writing), this XGBoost algorithm version doesn't fully support string categorical features.\n",
    "\n",
    "Below we **one-hot encode the categorical fields**, and then split the pre-processed data into randomly shuffled training, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b662d36-7e35-4cb2-9dc1-d80376386b9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'full_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_model_data \u001b[39m=\u001b[39m full_df\u001b[39m.\u001b[39mdrop(\n\u001b[1;32m      2\u001b[0m     columns\u001b[39m=\u001b[39m[\n\u001b[1;32m      3\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPassengerID\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mEventTime\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mwrite_time\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mapi_invocation_time\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mis_deleted\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mrow_number\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m     ],\n\u001b[1;32m      5\u001b[0m     errors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m,  \u001b[39m# Your DF may not have 'row_number' if you didn't do a time travel query\u001b[39;00m\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m df_model_data\n\u001b[1;32m      9\u001b[0m \u001b[39m# One-hot encode categorical variables:\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'full_df' is not defined"
     ]
    }
   ],
   "source": [
    "df_model_data = full_df.drop(\n",
    "    columns=[\n",
    "        \"passengerid\", \"eventtime\", \"write_time\", \"api_invocation_time\", \"is_deleted\", \"row_number\"\n",
    "    ],\n",
    "    errors=\"ignore\",  # Your DF may not have 'row_number' if you didn't do a time travel query\n",
    ")\n",
    "df_model_data\n",
    "\n",
    "# One-hot encode categorical variables:\n",
    "df_model_data = pd.get_dummies(df_model_data, dtype=int)\n",
    "\n",
    "# Shuffle and splitting dataset\n",
    "train_data, validation_data, test_data = np.split(\n",
    "    df_model_data.sample(frac=1, random_state=1729),\n",
    "    [int(0.7 * len(df_model_data)), int(0.9 * len(df_model_data))],\n",
    ")\n",
    "\n",
    "# Create CSV files for Train / Validation / Test\n",
    "train_data.to_csv(\"data/train.csv\", index=False, header=False)\n",
    "validation_data.to_csv(\"data/validation.csv\", index=False, header=False)\n",
    "test_data.to_csv(\"data/test.csv\", index=False, header=False)\n",
    "\n",
    "df_model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f5be5c-e9a5-4252-8350-40d83be79f98",
   "metadata": {},
   "source": [
    "The datasets specific for this algorithm can then be uploaded to Amazon S3, ready to use as inputs to the training job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f647af3b-78e1-491e-a98a-d4af7472a7ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_data_s3uri = f\"s3://{bucket_name}/{bucket_prefix}/model-data-xgb\"\n",
    "\n",
    "train_data_s3uri = model_data_s3uri + \"/train/data.csv\"\n",
    "train_data.to_csv(train_data_s3uri, index=False, header=False)\n",
    "validation_data_s3uri = model_data_s3uri + \"/validation/data.csv\"\n",
    "validation_data.to_csv(validation_data_s3uri, index=False, header=False)\n",
    "test_data_s3uri = model_data_s3uri + \"/test/data.csv\"\n",
    "test_data.to_csv(test_data_s3uri, index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557239c8-2c83-44b0-be71-ac84d24b1825",
   "metadata": {},
   "source": [
    "### Train a model\n",
    "\n",
    "With the data prepared in a compatible format, and the parameters collected, we're ready to run a training job through the SageMaker SDK [Estimator](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html) class, which provides a high-level wrapper over the underlying [SageMaker CreateTrainingJob API](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateTrainingJob.html).\n",
    "\n",
    "The training job runs on **separate, containerized infrastructure** from this notebook:\n",
    "\n",
    "- **You specify** the number and type of instances, and the IAM permissions with which the job runs (which could be separate from the notebook execution role)\n",
    "- The job is **independent** from the notebook: The input parameters, logs, metrics, and output artifacts are still available through the APIs even if the notebook disconnects/restarts part way through. (See [Estimator.attach(...)](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html#sagemaker.estimator.Estimator.attach) classmethod for re-attaching to previous/ongoing jobs).\n",
    "- A range of **other infrastructure parameters** are available like:\n",
    "    - [SageMaker managed spot](https://docs.aws.amazon.com/sagemaker/latest/dg/model-managed-spot-training.html), to optimize infrastructure costs\n",
    "    - [Warm pool keep-alive](https://docs.aws.amazon.com/sagemaker/latest/dg/train-warm-pools.html), to speed up start of sequential jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717597e0-ee03-4f33-86e2-afaf3aa39e19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "xgb_estimator = sagemaker.estimator.Estimator(\n",
    "    base_job_name=\"xgboost\",\n",
    "    role=sgmk_role,  # IAM role for job permissions (to access the S3 data)\n",
    "    image_uri=image_uri,  # XGBoost algorithm container\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",  # Type of compute instance\n",
    "    max_run=25 * 60,  # Limit job to 25 minutes\n",
    "\n",
    "    # OPTIONALLY use spot instances to reduce cost:\n",
    "    use_spot_instances=True,\n",
    "    max_wait=30 * 60,  # Maximum clock time (including spot delays)\n",
    "\n",
    "    output_path=f\"s3://{bucket_name}/{bucket_prefix}/train-output\",\n",
    ")\n",
    "\n",
    "xgb_estimator.set_hyperparameters(\n",
    "    num_round=50,\n",
    "    max_depth=5,\n",
    "    alpha=2.5,\n",
    "    eta=0.5,\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"auc\",\n",
    ")\n",
    "\n",
    "# Launch a SageMaker Training job by passing the S3 path of the datasets:\n",
    "xgb_estimator.fit({\n",
    "    \"train\": sagemaker.inputs.TrainingInput(train_data_s3uri, content_type=\"csv\"),\n",
    "    \"validation\": sagemaker.inputs.TrainingInput(validation_data_s3uri, content_type=\"csv\"),\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8963e739-5376-4c7a-b367-e810dc434e3e",
   "metadata": {},
   "source": [
    "As well as the logs streamed to the notebook, you can follow the status of the job in:\n",
    "- The [Training > Training jobs page of the AWS Console for SageMaker](https://console.aws.amazon.com/sagemaker/home?#/jobs)\n",
    "    - Including links to Amazon CloudWatch console to drill in to job logs and metric graphs\n",
    "- The Resources > Experiments and trials pane in SageMaker Studio\n",
    "    - Jobs started without an explicit Experiment configuration will appear under the \"Unassigned trial components\" folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139c4d06-6890-4dbe-beff-7c4a54215ef6",
   "metadata": {},
   "source": [
    "### Batch inference\n",
    "\n",
    "Once the model is trained, we can either deploy it to a real-time endpoint to make inference requests on-demand, or use it to run batch jobs on existing datasets.\n",
    "\n",
    "In this first example, we'll use [SageMaker Batch Transform](https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html) to run batch inference. SageMaker will spin up a temporary cluster, send our data through the model, and shut down the resources as soon as all the input data is processed.\n",
    "\n",
    "To get started, you can create a [Transformer object](https://sagemaker.readthedocs.io/en/stable/api/inference/transformer.html) directly from `estimator.transformer(...)`. However, in this we'll go via `create_model()` first so we can easily add the model to SageMaker Model Registry later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ecdae4-2d56-48ec-8514-146a5046ba86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xgb_model = xgb_estimator.create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9e2c7d-84fc-4d1b-a359-143e9cfbffd3",
   "metadata": {},
   "source": [
    "Because SageMaker Batch Transform orchestrates the process of sending data through the model and consolidating the outputs, there are a range of extra parameters beyond the basic S3 output location and instance size/type.\n",
    "\n",
    "By default, SageMaker Batch Transform treats each file in the input S3 prefix as one request payload and generates an output file of the same name, appending `.out`. Below we configure more specific handling for tabular data though:\n",
    "\n",
    "- Interpret each line of input files as a separate record with `split_type`, and interpret each line of output data as separate record with `assemble_with`.\n",
    "- Make `MultiRecord` batch requests up to `max_payload` Megabytes each - allowing up to `max_concurrent_transforms` concurrent requests per instance.\n",
    "- Exclude the `y` target label column (which is present in the test data) from model requests with `input_filter`.\n",
    "- Include the input data as well as the predictions in the result with `join_source`.\n",
    "\n",
    "The result will still be a single `.csv.out` file for each `.csv` input, but SageMaker has control of individual request batch sizes to optimize resource use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88304a6-8477-4e1f-83cb-0f031868ee6f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_s3uri = f\"s3://{bucket_name}/{bucket_prefix}/xgb-evaluation\"\n",
    "\n",
    "xgb_transformer = xgb_model.transformer(\n",
    "    output_path=eval_s3uri,  # S3 output location\n",
    "    instance_count=1,  # Number of instances to spin up for the job\n",
    "    instance_type=\"ml.m5.large\",  # Instance type to use for inference\n",
    "    strategy=\"MultiRecord\",  # Request inference in batches, for efficiency\n",
    "    accept=\"text/csv\",  # Request CSV response format\n",
    "    assemble_with=\"Line\",  # Consolidate response records with newlines between\n",
    "    max_concurrent_transforms=2,  # Instances sent up to N requests concurrently\n",
    "    max_payload=1,  # Max size per request (in Megabytes)\n",
    ")\n",
    "\n",
    "xgb_transformer.base_transform_job_name=\"sm101-dm-xgboost\"\n",
    "xgb_transformer.transform(\n",
    "    test_data_s3uri,\n",
    "    content_type=\"text/csv\",  # Test data is in CSV format\n",
    "    split_type=\"Line\",  # Each line of test data is a separate record\n",
    "    join_source=\"Input\",  # Output joined data including the input features as well as prediction\n",
    "    input_filter=\"$[1:]\",  # Exclude the leading (actual target value) field\n",
    "    # wait=True,  # (Default True) Block the notebook kernel until the job completes\n",
    "    # logs=True,  # (Default True) Stream job logs to the notebook\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b50bd3-c8a0-45a7-936e-40b96df0bf0b",
   "metadata": {},
   "source": [
    "Once the job completes, we can read the dataframe direct from Amazon S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69aa6cad-a63f-4454-aea3-7f5c978a3d7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_eval = pd.read_csv(\n",
    "    eval_s3uri + \"/data.csv.out\",\n",
    "    header=None,\n",
    "    names=test_data.columns.tolist() + [\"prob_survive\"],\n",
    ")\n",
    "df_eval"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "87dc290b-0080-45ce-9acf-1e688cd35d2d",
   "metadata": {},
   "source": [
    "To generate a report for the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad40ac6c-dd50-4c26-8484-7d681bb0a64c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "report = util.reporting.generate_binary_classification_report(\n",
    "    y_real=df_eval[\"survived\"].values,\n",
    "    y_predict_proba=df_eval[\"prob_survive\"].values,\n",
    "    class_names_list=[\"Died\", \"Lived\"],\n",
    "    title=\"Initial XGBoost model\",\n",
    ")\n",
    "\n",
    "# Store the model quality report locally and on Amazon S3:\n",
    "with open(\"data/report-xgboost.json\", \"w\") as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "model_quality_s3uri = f\"s3://{bucket_name}/{bucket_prefix}/{xgb_model.name}/model-quality.json\"\n",
    "!aws s3 cp data/report-xgboost.json {model_quality_s3uri}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11be4fa5-68e7-43d6-b285-644eea4bd9c8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Register and share the model\n",
    "\n",
    "The trained model is already available in the SageMaker APIs to deploy and re-use (you should see it, for example, in the [Models page of the SageMaker Console](https://console.aws.amazon.com/sagemaker/home?#/models)).\n",
    "\n",
    "However, we can improve discoverability and governance by cataloging it in the [SageMaker Model Registry](https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry.html). Here extra metadata can be associated, including I/O formats and the model quality report generated above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2199e4e7-7f86-4076-b974-3c0bacc6c9f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xgb_model.register(\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    model_package_group_name=\"awscc-uw-sm-dm\",\n",
    "    description=\"Initial XGBoost model\",\n",
    "    model_metrics=sagemaker.model_metrics.ModelMetrics(\n",
    "        model_statistics=sagemaker.model_metrics.MetricsSource(\n",
    "            content_type=\"application/json\",\n",
    "            s3_uri=model_quality_s3uri,\n",
    "        ),\n",
    "    ),\n",
    "    domain=\"MACHINE_LEARNING\",\n",
    "    task=\"CLASSIFICATION\",\n",
    "    sample_payload_url=test_data_s3uri,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b9aa2d-254f-4eff-af2c-a10785c0fa08",
   "metadata": {},
   "source": [
    "You can explore and manage your versioned registry model packages in SageMaker Studio: Including **reviewing and approving** new versions to trigger automated deployments."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e0fbc0c2-a74f-4680-8c31-37a5e354827d",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "In this notebook, we saw how [SageMaker Canvas AutoML](https://aws.amazon.com/sagemaker/canvas/) can accelerate new tabular ML projects to a high-accuracy, deployable model with no coding required. We also saw how you can dive deeper using the [SageMaker built-in algorithms](https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html) to customize your models without implementing common algorithms from scratch.\n",
    "\n",
    "We also saw brief intros to how [SageMaker Feature Store](https://docs.aws.amazon.com/sagemaker/latest/dg/feature-store.html) can help catalog shared feature data, and how [SageMaker Model Registry](https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry.html) helps with tracking and managing trained models. For more information on these MLOps features, you can refer to the documentation and the official [SageMaker notebook examples repository](https://github.com/aws/amazon-sagemaker-examples)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b27a8fd9",
   "metadata": {},
   "source": [
    "# IMPORTANT\n",
    "### STAY UNTIL THE END TO LEARN HOW TO FREE UP CLOUD RESOURCES TO AVOID BEING CHARGED"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15 (main, Nov 10 2011, 15:00:00) [GCC 12.2.0]"
  },
  "toc-showmarkdowntxt": false,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
